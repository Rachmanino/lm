{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 19.487179487179485,
  "eval_steps": 500,
  "global_step": 380,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.2564102564102564,
      "grad_norm": 1.8139944076538086,
      "learning_rate": 4.997864395968252e-05,
      "loss": 3.0407,
      "step": 5
    },
    {
      "epoch": 0.5128205128205128,
      "grad_norm": 1.1784621477127075,
      "learning_rate": 4.991461232516675e-05,
      "loss": 2.7338,
      "step": 10
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 0.8690347075462341,
      "learning_rate": 4.980801449342613e-05,
      "loss": 2.5749,
      "step": 15
    },
    {
      "epoch": 1.0256410256410255,
      "grad_norm": 0.9013162851333618,
      "learning_rate": 4.965903258506806e-05,
      "loss": 2.6963,
      "step": 20
    },
    {
      "epoch": 1.282051282051282,
      "grad_norm": 0.6799821853637695,
      "learning_rate": 4.946792113318386e-05,
      "loss": 2.3828,
      "step": 25
    },
    {
      "epoch": 1.5384615384615383,
      "grad_norm": 0.23267312347888947,
      "learning_rate": 4.923500664848326e-05,
      "loss": 2.083,
      "step": 30
    },
    {
      "epoch": 1.7948717948717947,
      "grad_norm": 0.31001728773117065,
      "learning_rate": 4.8960687061456324e-05,
      "loss": 2.4005,
      "step": 35
    },
    {
      "epoch": 2.051282051282051,
      "grad_norm": 0.34738245606422424,
      "learning_rate": 4.864543104251587e-05,
      "loss": 2.3211,
      "step": 40
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.4802488386631012,
      "learning_rate": 4.8289777201281974e-05,
      "loss": 2.1885,
      "step": 45
    },
    {
      "epoch": 2.564102564102564,
      "grad_norm": 0.354165256023407,
      "learning_rate": 4.789433316637644e-05,
      "loss": 2.1101,
      "step": 50
    },
    {
      "epoch": 2.8205128205128203,
      "grad_norm": 0.27816519141197205,
      "learning_rate": 4.7459774547299475e-05,
      "loss": 2.1682,
      "step": 55
    },
    {
      "epoch": 3.076923076923077,
      "grad_norm": 0.4631872773170471,
      "learning_rate": 4.698684378016222e-05,
      "loss": 2.3304,
      "step": 60
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.43698230385780334,
      "learning_rate": 4.6476348859247134e-05,
      "loss": 2.1371,
      "step": 65
    },
    {
      "epoch": 3.58974358974359,
      "grad_norm": 0.4681631922721863,
      "learning_rate": 4.592916195656322e-05,
      "loss": 2.0934,
      "step": 70
    },
    {
      "epoch": 3.8461538461538463,
      "grad_norm": 0.4313279688358307,
      "learning_rate": 4.534621793175487e-05,
      "loss": 2.0501,
      "step": 75
    },
    {
      "epoch": 4.102564102564102,
      "grad_norm": 0.39730343222618103,
      "learning_rate": 4.4728512734909844e-05,
      "loss": 2.3153,
      "step": 80
    },
    {
      "epoch": 4.358974358974359,
      "grad_norm": 0.39063364267349243,
      "learning_rate": 4.4077101704995166e-05,
      "loss": 2.0583,
      "step": 85
    },
    {
      "epoch": 4.615384615384615,
      "grad_norm": 0.5498151183128357,
      "learning_rate": 4.3393097766828293e-05,
      "loss": 2.003,
      "step": 90
    },
    {
      "epoch": 4.871794871794872,
      "grad_norm": 0.5023790001869202,
      "learning_rate": 4.267766952966369e-05,
      "loss": 2.071,
      "step": 95
    },
    {
      "epoch": 5.128205128205128,
      "grad_norm": 0.4216616153717041,
      "learning_rate": 4.193203929064353e-05,
      "loss": 2.1313,
      "step": 100
    },
    {
      "epoch": 5.384615384615385,
      "grad_norm": 0.6622089743614197,
      "learning_rate": 4.115748094652352e-05,
      "loss": 1.973,
      "step": 105
    },
    {
      "epoch": 5.641025641025641,
      "grad_norm": 0.6300293803215027,
      "learning_rate": 4.03553178172417e-05,
      "loss": 2.0174,
      "step": 110
    },
    {
      "epoch": 5.897435897435898,
      "grad_norm": 0.6417622566223145,
      "learning_rate": 3.952692038504846e-05,
      "loss": 2.0127,
      "step": 115
    },
    {
      "epoch": 6.153846153846154,
      "grad_norm": 0.7413439154624939,
      "learning_rate": 3.867370395306068e-05,
      "loss": 1.9902,
      "step": 120
    },
    {
      "epoch": 6.410256410256411,
      "grad_norm": 0.9254886507987976,
      "learning_rate": 3.779712622724003e-05,
      "loss": 1.8823,
      "step": 125
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 0.8278433084487915,
      "learning_rate": 3.689868482592684e-05,
      "loss": 1.8299,
      "step": 130
    },
    {
      "epoch": 6.923076923076923,
      "grad_norm": 0.9584782719612122,
      "learning_rate": 3.597991472118426e-05,
      "loss": 1.8479,
      "step": 135
    },
    {
      "epoch": 7.17948717948718,
      "grad_norm": 0.863292932510376,
      "learning_rate": 3.504238561632424e-05,
      "loss": 1.8467,
      "step": 140
    },
    {
      "epoch": 7.435897435897436,
      "grad_norm": 1.195220947265625,
      "learning_rate": 3.4087699264095745e-05,
      "loss": 1.6976,
      "step": 145
    },
    {
      "epoch": 7.6923076923076925,
      "grad_norm": 1.566406488418579,
      "learning_rate": 3.311748673011709e-05,
      "loss": 1.8471,
      "step": 150
    },
    {
      "epoch": 7.948717948717949,
      "grad_norm": 1.6763646602630615,
      "learning_rate": 3.213340560622763e-05,
      "loss": 1.6764,
      "step": 155
    },
    {
      "epoch": 8.205128205128204,
      "grad_norm": 2.099318265914917,
      "learning_rate": 3.1137137178519985e-05,
      "loss": 1.7906,
      "step": 160
    },
    {
      "epoch": 8.461538461538462,
      "grad_norm": 1.772552728652954,
      "learning_rate": 3.0130383554890856e-05,
      "loss": 1.6091,
      "step": 165
    },
    {
      "epoch": 8.717948717948717,
      "grad_norm": 2.182251214981079,
      "learning_rate": 2.9114864757018352e-05,
      "loss": 1.5236,
      "step": 170
    },
    {
      "epoch": 8.974358974358974,
      "grad_norm": 1.6722667217254639,
      "learning_rate": 2.8092315781733696e-05,
      "loss": 1.534,
      "step": 175
    },
    {
      "epoch": 9.23076923076923,
      "grad_norm": 2.0438621044158936,
      "learning_rate": 2.7064483636808313e-05,
      "loss": 1.6991,
      "step": 180
    },
    {
      "epoch": 9.487179487179487,
      "grad_norm": 2.0708987712860107,
      "learning_rate": 2.6033124356220328e-05,
      "loss": 1.3086,
      "step": 185
    },
    {
      "epoch": 9.743589743589745,
      "grad_norm": 2.530425786972046,
      "learning_rate": 2.5e-05,
      "loss": 1.5322,
      "step": 190
    },
    {
      "epoch": 10.0,
      "grad_norm": 2.5742111206054688,
      "learning_rate": 2.3966875643779667e-05,
      "loss": 1.5049,
      "step": 195
    },
    {
      "epoch": 10.256410256410255,
      "grad_norm": 2.1907637119293213,
      "learning_rate": 2.2935516363191693e-05,
      "loss": 1.2985,
      "step": 200
    },
    {
      "epoch": 10.512820512820513,
      "grad_norm": 1.9674642086029053,
      "learning_rate": 2.190768421826631e-05,
      "loss": 1.3009,
      "step": 205
    },
    {
      "epoch": 10.76923076923077,
      "grad_norm": 2.4208109378814697,
      "learning_rate": 2.088513524298165e-05,
      "loss": 1.3043,
      "step": 210
    },
    {
      "epoch": 11.025641025641026,
      "grad_norm": 6.889182090759277,
      "learning_rate": 1.9869616445109147e-05,
      "loss": 1.5162,
      "step": 215
    },
    {
      "epoch": 11.282051282051283,
      "grad_norm": 2.56598162651062,
      "learning_rate": 1.8862862821480025e-05,
      "loss": 1.1593,
      "step": 220
    },
    {
      "epoch": 11.538461538461538,
      "grad_norm": 2.4511375427246094,
      "learning_rate": 1.7866594393772373e-05,
      "loss": 1.1442,
      "step": 225
    },
    {
      "epoch": 11.794871794871796,
      "grad_norm": 3.1490864753723145,
      "learning_rate": 1.6882513269882917e-05,
      "loss": 1.282,
      "step": 230
    },
    {
      "epoch": 12.051282051282051,
      "grad_norm": 3.19770884513855,
      "learning_rate": 1.591230073590425e-05,
      "loss": 1.2188,
      "step": 235
    },
    {
      "epoch": 12.307692307692308,
      "grad_norm": 2.935333251953125,
      "learning_rate": 1.495761438367577e-05,
      "loss": 1.1018,
      "step": 240
    },
    {
      "epoch": 12.564102564102564,
      "grad_norm": 4.176358699798584,
      "learning_rate": 1.4020085278815745e-05,
      "loss": 1.0436,
      "step": 245
    },
    {
      "epoch": 12.820512820512821,
      "grad_norm": 3.1591665744781494,
      "learning_rate": 1.3101315174073162e-05,
      "loss": 1.1201,
      "step": 250
    },
    {
      "epoch": 13.076923076923077,
      "grad_norm": 3.0294902324676514,
      "learning_rate": 1.2202873772759981e-05,
      "loss": 1.1232,
      "step": 255
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 3.1161253452301025,
      "learning_rate": 1.1326296046939333e-05,
      "loss": 1.0173,
      "step": 260
    },
    {
      "epoch": 13.58974358974359,
      "grad_norm": 2.4542999267578125,
      "learning_rate": 1.0473079614951545e-05,
      "loss": 1.0199,
      "step": 265
    },
    {
      "epoch": 13.846153846153847,
      "grad_norm": 3.166835308074951,
      "learning_rate": 9.644682182758306e-06,
      "loss": 1.0324,
      "step": 270
    },
    {
      "epoch": 14.102564102564102,
      "grad_norm": 2.574645757675171,
      "learning_rate": 8.842519053476476e-06,
      "loss": 1.1024,
      "step": 275
    },
    {
      "epoch": 14.35897435897436,
      "grad_norm": 3.252364158630371,
      "learning_rate": 8.067960709356478e-06,
      "loss": 0.9254,
      "step": 280
    },
    {
      "epoch": 14.615384615384615,
      "grad_norm": 3.0896317958831787,
      "learning_rate": 7.3223304703363135e-06,
      "loss": 0.9439,
      "step": 285
    },
    {
      "epoch": 14.871794871794872,
      "grad_norm": 2.9328179359436035,
      "learning_rate": 6.606902233171711e-06,
      "loss": 1.0024,
      "step": 290
    },
    {
      "epoch": 15.128205128205128,
      "grad_norm": 3.1444787979125977,
      "learning_rate": 5.9228982950048416e-06,
      "loss": 1.1165,
      "step": 295
    },
    {
      "epoch": 15.384615384615385,
      "grad_norm": 2.545170307159424,
      "learning_rate": 5.271487265090163e-06,
      "loss": 0.87,
      "step": 300
    },
    {
      "epoch": 15.64102564102564,
      "grad_norm": 3.845503091812134,
      "learning_rate": 4.653782068245127e-06,
      "loss": 0.9558,
      "step": 305
    },
    {
      "epoch": 15.897435897435898,
      "grad_norm": 3.4977660179138184,
      "learning_rate": 4.070838043436786e-06,
      "loss": 0.8828,
      "step": 310
    },
    {
      "epoch": 16.153846153846153,
      "grad_norm": 4.053330898284912,
      "learning_rate": 3.523651140752868e-06,
      "loss": 1.0189,
      "step": 315
    },
    {
      "epoch": 16.41025641025641,
      "grad_norm": 2.2164502143859863,
      "learning_rate": 3.013156219837776e-06,
      "loss": 0.8369,
      "step": 320
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 2.885181427001953,
      "learning_rate": 2.5402254527005287e-06,
      "loss": 0.9321,
      "step": 325
    },
    {
      "epoch": 16.923076923076923,
      "grad_norm": 3.5240607261657715,
      "learning_rate": 2.1056668336235622e-06,
      "loss": 0.876,
      "step": 330
    },
    {
      "epoch": 17.17948717948718,
      "grad_norm": 1.664940595626831,
      "learning_rate": 1.710222798718028e-06,
      "loss": 1.0079,
      "step": 335
    },
    {
      "epoch": 17.435897435897434,
      "grad_norm": 3.135725975036621,
      "learning_rate": 1.3545689574841342e-06,
      "loss": 0.8858,
      "step": 340
    },
    {
      "epoch": 17.692307692307693,
      "grad_norm": 3.10577654838562,
      "learning_rate": 1.0393129385436824e-06,
      "loss": 0.8151,
      "step": 345
    },
    {
      "epoch": 17.94871794871795,
      "grad_norm": 3.2832798957824707,
      "learning_rate": 7.649933515167407e-07,
      "loss": 0.7986,
      "step": 350
    },
    {
      "epoch": 18.205128205128204,
      "grad_norm": 3.32071852684021,
      "learning_rate": 5.32078866816138e-07,
      "loss": 1.052,
      "step": 355
    },
    {
      "epoch": 18.46153846153846,
      "grad_norm": 3.0359866619110107,
      "learning_rate": 3.4096741493194197e-07,
      "loss": 0.836,
      "step": 360
    },
    {
      "epoch": 18.71794871794872,
      "grad_norm": 2.439527988433838,
      "learning_rate": 1.919855065738746e-07,
      "loss": 0.8893,
      "step": 365
    },
    {
      "epoch": 18.974358974358974,
      "grad_norm": 3.289367198944092,
      "learning_rate": 8.538767483325383e-08,
      "loss": 0.8162,
      "step": 370
    },
    {
      "epoch": 19.23076923076923,
      "grad_norm": 3.3464560508728027,
      "learning_rate": 2.1356040317474512e-08,
      "loss": 0.8992,
      "step": 375
    },
    {
      "epoch": 19.487179487179485,
      "grad_norm": 3.804185390472412,
      "learning_rate": 0.0,
      "loss": 0.8843,
      "step": 380
    },
    {
      "epoch": 19.487179487179485,
      "step": 380,
      "total_flos": 8.189155687071744e+16,
      "train_loss": 1.5400423802827534,
      "train_runtime": 1608.8751,
      "train_samples_per_second": 3.866,
      "train_steps_per_second": 0.236
    }
  ],
  "logging_steps": 5,
  "max_steps": 380,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 8.189155687071744e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
